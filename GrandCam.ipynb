{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwwTjUWmd4LY"
   },
   "source": [
    "#Install Library"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YiiyEbUdeMFW",
    "outputId": "231fdc13-f9e0-408a-d33e-7124f2087d51"
   },
   "source": [
    "pip install grad-cam -q"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LsxRzu8TeEnb",
    "outputId": "ad358bb6-ebb2-4416-9cac-f1771e942045"
   },
   "source": [
    "# Install Timm (Need to restart the runtime after finish install )\n",
    "!pip install git+https://github.com/rwightman/pytorch-image-models.git\n",
    "!pip install lightning transformers datasets evaluate pillow==9.2.0"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0A0s1NVmeQMM"
   },
   "source": [
    "⚠ ☝ Restart runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w979qmUverdT"
   },
   "source": [
    "##Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M0IHRiA8e5hr",
    "outputId": "cbb5034b-d688-441d-e2c9-26490ba2c8a6"
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Td7PTn8PfATK"
   },
   "source": [
    "!cp /content/drive/MyDrive/Datasets/Datasets.zip .\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jPMadzrpe35D",
    "outputId": "a9df0356-44b9-4bf9-cd33-3cc8a210a7ab"
   },
   "source": [
    "!unzip '/content/drive/MyDrive/Datasets/Datasets.zip' -d '/content/'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2xHxWft7fRjD"
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "\n",
    "# Pytorch Image model (TIMM) library: a library for state-of-the-art image classification\n",
    "import timm\n",
    "import timm.optim\n",
    "import timm.scheduler\n",
    "from timm.data import ImageDataset, create_dataset, create_loader\n",
    "from timm.data.transforms_factory import create_transform\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "from PIL import Image\n",
    "\n",
    "import evaluate\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "\n",
    "from lightning.fabric import Fabric\n",
    "\n",
    "from copy import copy\n",
    "\n",
    "import shutil\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eSA4nws7fbd4",
    "outputId": "48030f80-6a49-4497-a4c9-1ea5526ffdc4"
   },
   "source": [
    "try:\n",
    "    from torchinfo import summary\n",
    "except:\n",
    "    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
    "    !pip install -q torchinfo\n",
    "    from torchinfo import summary"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lQjBl_N9f_-7"
   },
   "source": [
    "#Grand CAM"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EGFTriK_glW7"
   },
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "import cv2\n",
    "import requests\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image, \\\n",
    "    deprocess_image, \\\n",
    "    preprocess_image\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p9yn9ypRVpN9",
    "outputId": "3d71d52e-de54-4b77-92a2-597c23417c83"
   },
   "source": [
    "import os\n",
    "\n",
    "source_dir = '/content/3_cls/test'\n",
    "\n",
    "img_paths = []\n",
    "\n",
    "for root , dir, files in os.walk(source_dir):\n",
    "  for file in files:\n",
    "    file_path = os.path.join(root,file)\n",
    "    img_paths.append(file_path)\n",
    "print(len(img_paths))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LxZFVnK_EAWR",
    "outputId": "72150bb3-ff37-49cf-d058-05b38e7598a6"
   },
   "source": [
    "import os\n",
    "# Define the directory paths\n",
    "test_ad = '/content/drive/MyDrive/Datasets/3_cls/test/AD'\n",
    "test_control = '/content/drive/MyDrive/Datasets/3_cls/test/CONTROL'\n",
    "test_pd = '/content/drive/MyDrive/Datasets/3_cls/test/PD'\n",
    "\n",
    "train_pd = '/content/drive/MyDrive/Datasets/3_cls/train/PD'\n",
    "train_ad = '/content/drive/MyDrive/Datasets/3_cls/train/AD'\n",
    "train_control = '/content/drive/MyDrive/Datasets/3_cls/train/CONTROL'\n",
    "\n",
    "print(\"Test Ad: \",len(os.listdir(test_ad)))\n",
    "print(\"Train Ad: \",len(os.listdir(train_ad)))\n",
    "print(\"Test pd: \",len(os.listdir(test_pd)))\n",
    "print(\"Train pd: \",len(os.listdir(train_pd)))\n",
    "print(\"Train control: \",len(os.listdir(train_control)))\n",
    "print(\"Test control: \",len(os.listdir(test_control)))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JkJh00ysED95"
   },
   "source": [
    "model_path = '/content/efficientnet_b3.ra2_in1k'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x4WXr7zmBnHd",
    "outputId": "140475ed-9cc6-4dac-9100-06a1aeb0d3c6"
   },
   "source": [
    "# Select model\n",
    "mobilenetv3_large_100 =  timm.create_model('efficientnet_b3.ra2_in1k', pretrained=True)\n",
    "\n",
    "# Find the correct attribute name for the classifier layer\n",
    "# Print the model's children to inspect the layers\n",
    "for name, module in mobilenetv3_large_100.named_children():\n",
    "    print(name)\n",
    "\n",
    "# Assuming the classifier layer is named 'classifier', adjust as needed\n",
    "num_ftrs = mobilenetv3_large_100.classifier.in_features\n",
    "mobilenetv3_large_100.classifier = nn.Linear(in_features=num_ftrs, out_features=4)\n",
    "\n",
    "# Print a summary\n",
    "summary(model=mobilenetv3_large_100,\n",
    "        input_size=(16, 3, 224, 224),\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wSXVfXIiDFvI",
    "outputId": "e65d65cd-230c-4b9f-ed4b-09419bac44e2"
   },
   "source": [
    "print(model)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "id": "7Yi4bWvElWH5",
    "outputId": "427c3d32-5868-46af-998a-13cef0589cc5"
   },
   "source": [
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import timm\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image, preprocess_image\n",
    "\n",
    "# Load the model\n",
    "model = timm.create_model('efficientnet_b3.ra2_in1k', pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# Load and preprocess the image\n",
    "image_url = \"/content/3_cls/test/AD/AD_3108.png\"\n",
    "img = np.array(Image.open(image_url))\n",
    "img = cv2.resize(img, (224, 224))\n",
    "\n",
    "if img.ndim == 2:  # If the image is grayscale, convert to RGB\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "img = np.float32(img) / 255\n",
    "input_tensor = preprocess_image(img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# Select the target layer\n",
    "target_layers = [model.blocks[-1][-1].bn2]\n",
    "\n",
    "# Define the target class\n",
    "targets = [ClassifierOutputTarget(0)]\n",
    "\n",
    "# Generate the Grad-CAM\n",
    "with GradCAM(model=model, target_layers=target_layers) as cam:\n",
    "    grayscale_cams = cam(input_tensor=input_tensor, targets=targets)\n",
    "    cam_image = show_cam_on_image(img, grayscale_cams[0, :], use_rgb=True)\n",
    "\n",
    "# Display the results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cam = np.uint8(255 * grayscale_cams[0, :])\n",
    "cam = cv2.merge([cam, cam, cam])\n",
    "images = np.hstack((np.uint8(255 * img), cam, cam_image))\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axs[0].imshow(np.uint8(255 * img))\n",
    "axs[0].set_title('Original Image')\n",
    "axs[0].axis('off')\n",
    "\n",
    "axs[1].imshow(cam)\n",
    "axs[1].set_title('Grad-CAM')\n",
    "axs[1].axis('off')\n",
    "\n",
    "axs[2].imshow(cam_image)\n",
    "axs[2].set_title('Overlay Image')\n",
    "axs[2].axis('off')\n",
    "\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Q54gnHlsieWf"
   },
   "source": [
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import timm  # Import timm to load the model directly\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image, preprocess_image\n",
    "\n",
    "# Load the model directly from timm\n",
    "model = timm.create_model('efficientnet_b3.ra2_in1k', pretrained=True)\n",
    "model = model.eval()\n",
    "model = model.to('cpu')  # Move the model to CPU if needed\n",
    "\n",
    "# ... rest of your code (from cell 53)\n",
    "image_url = \"/content/3_cls/test/AD/AD_3108.png\"\n",
    "img = np.array(Image.open(image_url))\n",
    "# ... (continue with the rest of your code)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mwJ1g9_QgXp9"
   },
   "source": [
    "def grand_cam(img_path, model, class_idx):\n",
    "    # Load image and apply transforms\n",
    "    img = np.array(Image.open(img_path))\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "\n",
    "    # Check if the image is grayscale and convert to RGB if necessary\n",
    "    if img.ndim == 2:  # Grayscale image\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    img = np.float32(img) / 255\n",
    "    input_tensor = preprocess_image(img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    # Grad-CAM Process\n",
    "    targets = [ClassifierOutputTarget(class_idx)]\n",
    "\n",
    "    # Select the target layer from the last block of the model\n",
    "    target_layers = [model.blocks[-1][-1].bn2] # Changed line to select a valid layer\n",
    "\n",
    "    with GradCAM(model=model, target_layers=target_layers) as cam:\n",
    "        grayscale_cams = cam(input_tensor=input_tensor, targets=targets)\n",
    "        cam_image = show_cam_on_image(img, grayscale_cams[0, :], use_rgb=True)\n",
    "\n",
    "    cam = np.uint8(255 * grayscale_cams[0, :])\n",
    "    cam = cv2.merge([cam, cam, cam])\n",
    "    images = np.hstack((np.uint8(255 * img), cam, cam_image))\n",
    "    pil_image = Image.fromarray(images)\n",
    "    print(f\"Image : {os.path.basename(img_path)}\")\n",
    "    plt.imshow(pil_image)\n",
    "    plt.pause(0.1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 249
    },
    "id": "j8BGLKyMh5rv",
    "outputId": "c0c886fc-1eb6-4838-c759-f1b241c96425"
   },
   "source": [
    "# Call the function with the model and image path\n",
    "grand_cam('/content/3_cls/test/AD/AD_3108.png', model, 0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQmuj0wc4Yzw"
   },
   "source": [
    "#AD"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "wPDSFkRFkjOa",
    "outputId": "dde51a4f-b52b-4049-b6bc-a3b8567603ee"
   },
   "source": [
    "# Directory path and corresponding class index\n",
    "image_directory = '/content/3_cls/test/AD'\n",
    "image_paths = [os.path.join(image_directory, filename) for filename in os.listdir(image_directory) if filename.endswith('.png')]\n",
    "\n",
    "for img_path in image_paths:\n",
    "  grand_cam(img_path,model,0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RdXJkjnp4eQL"
   },
   "source": [
    "#CONTROL"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZKcGpZJWnKgE",
    "outputId": "d84ece9b-546c-497e-9fcb-a1c17ac9317d"
   },
   "source": [
    "# Directory path and corresponding class index\n",
    "image_directory = '/content/3_cls/test/CONTROL'\n",
    "image_paths = [os.path.join(image_directory, filename) for filename in os.listdir(image_directory) if filename.endswith('.png')]\n",
    "\n",
    "for img_path in image_paths:\n",
    "  grand_cam(img_path,model,1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7fFbNqNK4hLq"
   },
   "source": [
    "\n",
    "#PD"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fBYlJjMzpoJK"
   },
   "source": [
    "image_directory = '/content/3_cls/test/PD'\n",
    "image_paths = [os.path.join(image_directory, filename) for filename in os.listdir(image_directory) if filename.endswith('.png')]\n",
    "\n",
    "for img_path in image_paths:\n",
    "  grand_cam(img_path,model,2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "S8z2O1GVtSYC"
   },
   "source": [
    "def grand_cam(img_path, model, class_idx):\n",
    "    # Load image and apply transforms\n",
    "    img = np.array(Image.open(img_path))\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "\n",
    "    # Check if the image is grayscale and convert to RGB if necessary\n",
    "    if img.ndim == 2:  # Grayscale image\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    img = np.float32(img) / 255\n",
    "    input_tensor = preprocess_image(img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    # Grad-CAM Process\n",
    "    targets = [ClassifierOutputTarget(class_idx)]\n",
    "    target_layers = [model.blocks[-1]]  # Using the last block of EfficientNetV2\n",
    "\n",
    "    with GradCAM(model=model, target_layers=target_layers) as cam:\n",
    "        grayscale_cams = cam(input_tensor=input_tensor, targets=targets)\n",
    "        cam_image = show_cam_on_image(img, grayscale_cams[0, :], use_rgb=True)\n",
    "\n",
    "    cam = np.uint8(255 * grayscale_cams[0, :])\n",
    "    cam = cv2.merge([cam, cam, cam])\n",
    "    images = np.hstack((np.uint8(255 * img), cam, cam_image))\n",
    "    pil_image = Image.fromarray(images)\n",
    "    print(f\"Image : {os.path.basename(img_path)}\")\n",
    "    plt.imshow(pil_image)\n",
    "    plt.pause(0.1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 249
    },
    "id": "7SgxcazRO74f",
    "outputId": "4995b7e7-bc49-4072-9495-f7a22f9d04e4"
   },
   "source": [
    "img ='/content/3_cls/test/PD/PD_320.png'\n",
    "grand_cam(img, model, 3) # Added img as the first argument"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4UFEOjrOt0ur",
    "outputId": "48841481-6789-4fd8-ecaf-36373d4f5b58"
   },
   "source": [
    "image_directory = '/content/3_cls/test/AD'\n",
    "image_paths = [os.path.join(image_directory, filename) for filename in os.listdir(image_directory) if filename.endswith('.png')]\n",
    "\n",
    "for img_path in image_paths:\n",
    "  grand_cam(img_path,model,0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "lRhIk1K1uJtC",
    "outputId": "d3ea5c06-1bda-43bd-c970-10b083e9c63a"
   },
   "source": [
    "image_directory = '/content/3_cls/test/CONTROL'\n",
    "image_paths = [os.path.join(image_directory, filename) for filename in os.listdir(image_directory) if filename.endswith('.png')]\n",
    "\n",
    "for img_path in image_paths:\n",
    "  grand_cam(img_path,model,1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-8bt_FgDdJ85",
    "outputId": "0e21b628-e8a9-4ee0-d1a8-34cf104fd621"
   },
   "source": [
    "image_directory = '/content/3_cls/test/PD'\n",
    "image_paths = [os.path.join(image_directory, filename) for filename in os.listdir(image_directory) if filename.endswith('.png')]\n",
    "\n",
    "for img_path in image_paths:\n",
    "  grand_cam(img_path,model,2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "rlv2DRVgsF-G",
    "outputId": "7613ffde-e07d-4c97-a2a6-80fc3b161fd4"
   },
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_grad_cam import GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image, preprocess_image\n",
    "\n",
    "def grand_cam(img_path, model, class_idx, output_dir): # เพิ่ม output_dir\n",
    "    # Load image and apply transforms\n",
    "    img = np.array(Image.open(img_path))\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "\n",
    "    # Check if the image is grayscale and convert to RGB if necessary\n",
    "    if img.ndim == 2:  # Grayscale image\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    img = np.float32(img) / 255\n",
    "    input_tensor = preprocess_image(img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    # Grad-CAM Process\n",
    "    targets = [ClassifierOutputTarget(class_idx)]\n",
    "    target_layers = [model.blocks[-1]]  # Using the last block of EfficientNetV2\n",
    "\n",
    "    with GradCAM(model=model, target_layers=target_layers) as cam:\n",
    "        grayscale_cams = cam(input_tensor=input_tensor, targets=targets)\n",
    "        cam_image = show_cam_on_image(img, grayscale_cams[0, :], use_rgb=True)\n",
    "\n",
    "    cam = np.uint8(255 * grayscale_cams[0, :])\n",
    "    cam = cv2.merge([cam, cam, cam])\n",
    "    images = np.hstack((np.uint8(255 * img), cam, cam_image))\n",
    "    pil_image = Image.fromarray(images)\n",
    "    print(f\"Image : {os.path.basename(img_path)}\")\n",
    "    plt.imshow(pil_image)\n",
    "    plt.pause(0.1)\n",
    "\n",
    "    # บันทึกรูปลงไดรท์\n",
    "    output_filename = os.path.join(output_dir, os.path.basename(img_path))  # สร้างชื่อไฟล์สำหรับบันทึก\n",
    "    pil_image.save(output_filename)\n",
    "\n",
    "# ตัวอย่างการเรียกใช้\n",
    "output_base_dir = '/content/drive/MyDrive/images colab/GreandCam'  # แก้ไข path ตามต้องการ\n",
    "os.makedirs(output_base_dir, exist_ok=True)\n",
    "\n",
    "# Define image directories as a list\n",
    "image_directories = ['/content/3_cls/test/AD', '/content/3_cls/test/CONTROL', '/content/3_cls/test/PD']\n",
    "\n",
    "# Iterate through each directory\n",
    "for image_directory in image_directories:\n",
    "    image_paths = [os.path.join(image_directory, filename) for filename in os.listdir(image_directory) if filename.endswith('.png')]\n",
    "    for img_path in image_paths:\n",
    "        grand_cam(img_path, model, 0, output_base_dir)  # ส่ง output_dir ไปยัง grand_cam"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nkWkkDRx4zbx",
    "outputId": "27323449-4ef6-4920-9040-5389f887fcb3"
   },
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# สมมติให้ y_true คือข้อมูล label จริง และ y_pred คือผลลัพธ์ที่โมเดลทำนายได้\n",
    "# y_true และ y_pred จะเป็น array ที่มีค่าเป็น label (AD, CONTROL, PD) ของข้อมูลแต่ละตัวอย่าง\n",
    "\n",
    "# ตัวอย่างของ y_true และ y_pred (คุณต้องแทนที่ด้วยค่าจริงที่ได้จากโมเดลของคุณ)\n",
    "# Replace ellipsis with actual label values\n",
    "y_true = np.array(['AD', 'CONTROL', 'PD', 'CONTROL', 'AD', 'PD', 'AD'])\n",
    "y_pred = np.array(['AD', 'AD', 'PD', 'CONTROL', 'CONTROL', 'PD', 'CONTROL'])\n",
    "\n",
    "# คำนวณค่า confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred, labels=['AD', 'CONTROL', 'PD'])\n",
    "\n",
    "# คำนวณค่า Precision, Recall, F1 Score, และ Accuracy\n",
    "report = classification_report(y_true, y_pred, target_names=['AD', 'CONTROL', 'PD'])\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# แสดงผลลัพธ์\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report)\n",
    "print(f\"\\nAccuracy: {accuracy:.2f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qHzGDS0L5BJV",
    "outputId": "f77b8965-4d16-49ba-a086-baf21aab8f9d"
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "import timm\n",
    "\n",
    "# กำหนด transforms สำหรับการทำ Data Augmentation\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# โหลด dataset\n",
    "dataset = datasets.ImageFolder(root='/content/3_cls/test', transform=data_transforms)\n",
    "\n",
    "# แบ่ง dataset เป็น train และ test\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# สร้าง DataLoader สำหรับ train และ test\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# เลือกโมเดลที่จะใช้ (ในที่นี้ใช้ tf_efficientnetv2_b0.in1k จาก timm)\n",
    "model = timm.create_model('tf_efficientnetv2_b0.in1k', pretrained=True)\n",
    "model.classifier = nn.Linear(model.classifier.in_features, 3)  # กำหนด output ให้เท่ากับจำนวน class ที่มี\n",
    "\n",
    "# กำหนด loss function และ optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# การฝึกโมเดล\n",
    "num_epochs = 10\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# การทดสอบโมเดล\n",
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        y_true.extend(labels.numpy())\n",
    "        y_pred.extend(preds.numpy())\n",
    "\n",
    "# คำนวณค่า Precision, Recall, F1 Score, และ Accuracy\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=dataset.classes))\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
